# -*- coding: utf-8 -*-
"""resnet_50.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uu1ooVwzs1i_mkfEy7veDbdhUzoJ-hNZ
"""


import os
import datetime
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, Input
import tensorboard
from tensorboard.plugins.hparams import api as hp
from src.preprocessing.image_gen import MultiTaskImageGen2, BalanceImageGenerator, MultiTaskImageGen
from src.preprocessing.dataset_stuff import augment, separate_images
from src.applications.resnet_custom import make_model

# tf.__version__

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

TIMESTAMP = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
AUTOTUNE = tf.data.experimental.AUTOTUNE
DATADIR = 'gs://alexfyp_data'
LOGDIR = 'gs://alexfyp_logs'
BATCH_SIZE = 128
CLASS_LABELS = ['faw', 'zinc_def', 'nlb', 'healthy']

EPOCHS=200

feature_description = {
    'rows': tf.io.FixedLenFeature([1], tf.int64),
    'cols': tf.io.FixedLenFeature([1], tf.int64),
    'channels': tf.io.FixedLenFeature([1], tf.int64),
    'image': tf.io.FixedLenFeature([1], tf.string),
    'labels': tf.io.VarLenFeature(tf.float32)
}

train_files = [os.path.join(DATADIR, f'sharded/train/train{index}.tfrecord') for index in range(16)]
test_files = [os.path.join(DATADIR, f'sharded/test/test{index}.tfrecord') for index in range(8)]
val_files = [os.path.join(DATADIR, f'sharded/val/val{index}.tfrecord') for index in range(8)]

train = MultiTaskImageGen2(train_files, feature_description)
val = MultiTaskImageGen2(val_files, feature_description)
test = MultiTaskImageGen2(test_files, feature_description)

STEPS_PER_EPOCH = 39534//BATCH_SIZE
VAL_STEPS = 1921//BATCH_SIZE
TEST_STEPS = 4157/BATCH_SIZE
print(STEPS_PER_EPOCH, VAL_STEPS, TEST_STEPS)
print(train.get_num_images(), val.get_num_images(), test.get_num_images())

train_ds = train.get_all().cache().repeat().map(augment, num_parallel_calls=AUTOTUNE)\
                          .shuffle(2048).batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTOTUNE)
val_ds = val.get_all().cache().shuffle(1024).batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTOTUNE)
test_ds = test.get_all().shuffle(1024).batch(BATCH_SIZE, drop_remainder=True)

train_img = train.get_all().map(separate_images, num_parallel_calls=AUTOTUNE)

with strategy.scope():
  # norm = tf.keras.layers.experimental.preprocessing.Normalization(axis=(0,1,2))
  # norm.adapt(train_img)
  initializer = tf.keras.initializers.he_normal()
  loss = tf.keras.losses.BinaryCrossentropy()
  optimizer = tf.keras.optimizers.Adam()
  
  METRICS = [tf.keras.metrics.BinaryAccuracy(name='acc'),
             tf.keras.metrics.Precision(name='psn'),
             tf.keras.metrics.Recall(name='rcl'),
             tf.keras.metrics.AUC(name='AUC')]

  model = make_model((256,256,3), METRICS, optimizer, loss, 0.0,
                     input_normalizer=None, weights_initializer=initializer,
                     extra_layers=True)

model.summary()

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir gs://alexfyp_logs/resnet_adam2

logdir = os.path.join(LOGDIR, 'resnet_adam2')

reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,
                              patience=5)
checkpoint = tf.keras.callbacks.ModelCheckpoint('gs://alexfyp_models/resnet_adam2',
                  monitor='val_loss', verbose=0, save_best_only=True,
                  save_weights_only=False, mode='auto', save_freq='epoch')
log_tens = tf.keras.callbacks.TensorBoard(log_dir=logdir, write_graph=False)

model.fit(train_ds,
          epochs=EPOCHS,
          steps_per_epoch=307,
          validation_data=val_ds,
          callbacks=[reduce_lr, checkpoint, log_tens])

new_model = tf.keras.models.load_model('gs://alexfyp_models/resnet_adam2')

history = new_model.evaluate(test_ds)
history

hist = {}
hist['faw_acc'] = history[4]
hist['faw_psn'] = history[5]
hist['faw_rcl'] = history[6]
hist['faw_AUC'] = history[7]
hist['zinc_acc'] = history[8]
hist['zinc_psn'] = history[9]
hist['zinc_rcl'] = history[10]
hist['zinc_AUC'] = history[11]
hist['nlb_acc'] = history[12]
hist['nlb_psn'] = history[13]
hist['nlb_rcl'] = history[14]
hist['nlb_AUC'] = history[15]

hist
