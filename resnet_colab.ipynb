{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "import tensorboard\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from src.preprocessing.image_gen import MultiTaskImageGen2, BalanceImageGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='fyp',\n",
    "                                                          zone='europe-west4-a',\n",
    "                                                          project='eeefyp')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "strategy=tf.distribute.experimental.TPUStrategy(resolver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "DATADIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'data/clean')\n",
    "LOGDIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), f'logs/norm_exp/{TIMESTAMP}')\n",
    "BATCH_SIZE = 16\n",
    "CLASS_LABELS = ['FAW', 'zinc_def', 'healthy']\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    'rows': tf.io.FixedLenFeature([1], tf.int64),\n",
    "    'cols': tf.io.FixedLenFeature([1], tf.int64),\n",
    "    'channels': tf.io.FixedLenFeature([1], tf.int64),\n",
    "    'image': tf.io.FixedLenFeature([1], tf.string),\n",
    "    'labels': tf.io.VarLenFeature(tf.float32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_faw = MultiTaskImageGen2(os.path.join(DATADIR, 'final/faw.tfrecord'), feature_description)\n",
    "test_faw, val_faw = ds_faw.split_dataset()\n",
    "img_ds = ds_faw.get_train_img()\n",
    "\n",
    "ds_healthy = MultiTaskImageGen2(os.path.join(DATADIR, 'final/healthy.tfrecord'), feature_description)\n",
    "test_healthy, val_healthy = ds_healthy.split_dataset()\n",
    "img_ds = img_ds.concatenate(ds_healthy.get_train_img())\n",
    "\n",
    "ds_zinc = MultiTaskImageGen2(os.path.join(DATADIR, 'final/zinc_def.tfrecord'), feature_description)\n",
    "test_zinc, val_zinc = ds_zinc.split_dataset()\n",
    "img_ds = img_ds.concatenate(ds_zinc.get_train_img())\n",
    "\n",
    "# ds_nlb = MultiTaskImageGen(os.path.join(DATADIR, 'final/NLB/nlb'), 256, CLASS_LABELS)\n",
    "# ds_nlb_h = MultiTaskImageGen(os.path.join(DATADIR, 'final/NLB/nlb'), 256, CLASS_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_faw.concatenate(test_healthy)\n",
    "test = test.concatenate(test_zinc).shuffle(1000)\n",
    "test = test.batch(2*BATCH_SIZE)\n",
    "\n",
    "val = val_faw.concatenate(val_healthy)\n",
    "val = val.concatenate(val_zinc)\n",
    "val = val.batch(2*BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_healthy = len(os.listdir(os.path.join(DATADIR, 'final/healthy')))\n",
    "STEPS_PER_EPOCH = np.ceil(3*0.8*0.8*num_healthy/BATCH_SIZE)\n",
    "print(num_healthy, STEPS_PER_EPOCH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_ds = BalanceImageGenerator(BATCH_SIZE, ds_faw(), ds_healthy(), ds_zinc())()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.keras.initializers.he_normal()\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "METRICS = [tf.keras.metrics.BinaryAccuracy(name='acc'),\n",
    "            tf.keras.metrics.Precision(name='psn'),\n",
    "            tf.keras.metrics.Recall(name='rcl'),\n",
    "            tf.keras.metrics.AUC(name='AUC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = make_model((256,256,3), METRICS, optimizer, loss, initializer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(balance_ds,\n",
    "          epochs=100,\n",
    "          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "          validation_data=val,\n",
    "          callbacks=[tf.keras.callbacks.TensorBoard(log_dir=LOGDIR, histogram_freq=1),\n",
    "                     tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test, callbacks=[tf.keras.callbacks.TensorBoard(log_dir=LOGDIR)])"
   ]
  }
 ]
}